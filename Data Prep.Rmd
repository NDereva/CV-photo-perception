---
title: "Data prep"
author: "Mykola Dereva"
date: "5/18/2021"
output: html_document
---

## Project description

The project was inspired by this [blogpost](https://habr.com/ru/company/yandex_praktikum/blog/557256/) (in russian).

The idea is that they make questionnaire to check how CV photo influence on the subjective perception of candidate competency.

They claim that small smile on candidate's CV photo, slightly increase the perception of candidate competency

However, the blogpost lack of any kind of statistical data analysis and relies only on descriptive statistics.

Luckily they [shared the collected data](https://docs.google.com/spreadsheets/d/1QJbmdpYDQz5mpiqyg08Z5RuP--2q2m893to401wUbi0/edit#gid=41231417) of questionnaire, so I can play with the data on my own and check their findings.

## Load data

```{r message=FALSE}
rm(list = ls())
library(tidyverse)
library(here)
```

Set locale to display Russian characters properly

```{r}
Sys.setlocale("LC_CTYPE", "russian")
```

```{r message=FALSE}
d <- read_csv(here("raw data",
                   "How CV photo influence feel of competence (in Russia).csv"))
```

```{r}
head(d)
```

First of all, I need to translate data into english to make the further analysis easier Meanwhile, I will delete the columns I do not need for the analysis

```{r}
d <- d %>% 
  rename(resp_sex = `Укажите свой пол`,        # resp for responder
         resp_age = `Укажите свой возраст`,
         resp_hire = `Насколько часто вы участвуете в найме людей?`,
         cand_id = `Номер участника`,         #cand for candidate
         cand_sex = `Пол участника`,
         cand_smile = `Эмоция`,               
         cand_select = `Выбор участника`,     # which photo cand finds the best
         cand_competency = `Оценка`)          # subjective assessment of cand competency
```

```{r}
d <- d %>% 
  select(starts_with("resp"),
         starts_with("cand"))

d
```

## Transform variables to factor and translate


### trasform responder's sex
```{r}
d <- d %>% 
  mutate(resp_sex = if_else(resp_sex == "Женский", "F", "M")) %>% 
  mutate(resp_sex = as_factor(resp_sex))

d %>% 
  count(resp_sex)
```


### transform resp_age

```{r}
d %>% 
  count(resp_age)
```


```{r}
lvl <- c("<25", "26-35", "36-45", "46-55", ">56")

d <- d %>% 
  mutate(resp_age = if_else(resp_age == "до 25", "<25",  resp_age)) %>% 
  mutate(resp_age = if_else(resp_age == "больше 56", ">56", resp_age)) %>% 
  mutate(resp_age = factor(resp_age, levels = lvl))

```

```{r}
levels(d$resp_age)
```

### transform resp hire

This variable indicates how often the responder was involved with the hiring 
procedure

```{r}
d %>% count(resp_hire)
```

```{r}
d <- d %>% 
  mutate(resp_hire = case_when(resp_hire == "Никогда не участвовал" ~ "never",
                               resp_hire == "Иногда" ~ "sometimes",
         resp_hire ==  "Это часть моих рабочих обязанностей, участвую постоянно" ~ "always")) %>% 
  mutate(resp_hire = factor(resp_hire, levels = c("never", "sometimes", "always"))) 

```


```{r}
levels(d$resp_hire)
```

### transform cand_id

```{r}
d %>% count(cand_id)
```
each candidate has equal number of responses 

```{r}
d <- d %>% 
  mutate(cand_id = as_factor(cand_id))
```


### transform cand_sex

```{r}
d %>% count(cand_sex)
```
```{r}
d <- d %>% 
  mutate(cand_sex = if_else(cand_sex == "Ж", "F", "M")) %>% 
  mutate(cand_sex = as_factor(cand_sex))
```


### transform cand_smile

```{r}
d %>% count(cand_smile)
```

```{r}
d <- d %>% 
  mutate(cand_smile = case_when(cand_smile == "Серьезное лицо" ~ "no",
                                cand_smile == "Сдеражнная улыбка" ~ "small",
                                cand_smile == "Широкая улыбка" ~ "big")) %>% 
  mutate(cand_smile = factor(cand_smile, levels = c("no", "small", "big")))
```


```{r}
levels(d$cand_smile)
```


### transform cand_select

```{r}
table(d$cand_id, d$cand_select)
```

```{r}
d <- d %>% 
  mutate(cand_select = if_else(cand_select == "Да", 1, 0)) %>% 
  mutate(cand_select = as_factor(cand_select))
```


Each candidate submitted 3 photos. The photo which candidate think is the best
for CV have a value of 1 in cand_select variable


### transform cand_competency 

I will transform cand_competency so it lays between 0 and 1. 
To make setting priors easier

```{r}
d %>% count(cand_competency)
```


```{r}
d <- d %>% 
  mutate(cand_competency_fct = cand_competency) %>% 
  mutate(cand_competency = cand_competency / max(cand_competency))
```


```{r}
ggplot(d, aes(x = cand_competency)) +
  geom_histogram() +
  theme_minimal()
```







```{r}
head(d)
```

It seems that I have done with data preparation


## Modeling 

Lets try to fit simple model 
```{r}
library(brms)
library(tidybayes)
```


Lets start with the linear model just with intercepts for each smile type
Obviously linear model is not perfectly suitable because of the type of response 
variable. For example, the distance between 0 and 1 might be different with the 5 and 6 for.

### Intercept model

```{r}
m.1 <- 
  brm(data = d, 
      family = gaussian,
      cand_competency ~ 0 + cand_smile,   # 0 indicates that there is separate intercept
                                          # for each smile type
      prior = c(prior(normal(0.5, 0.25), class = b),
                prior(exponential(1), class = sigma)),
      iter = 2000, warmup = 1000, chains = 4, cores = 4,
      seed = 1,
      file = "fits/m.1")
```

```{r}
print(m.1)
```

```{r}
plot(m.1)
```

```{r}
mcmc_plot(m.1, pars = "b_")
```

The result resemble the one in the blogpost. 
Candidates with small smile look slightly more competent 


Lets try to fit model with random slopes varying across candidates

### Random slopes varying by candidate

```{r}
m.2 <- 
  brm(data = d, 
      family = gaussian,
      cand_competency ~ 0 + cand_smile + # separate intercept for each smile type
        (1 | cand_id),                   # varying intercept by candidates 
      prior = c(prior(normal(0.5, 0.25), class = b),
                prior(exponential(1), class = sigma)),
      iter = 2000, warmup = 1000, chains = 4, cores = 4,
      seed = 1,
      file = "fits/m.2")
```
model took 10 seconds to estimate

```{r}
print(m.2)
```


```{r}
mcmc_plot(m.2, pars = "b_")
```



### Varying slopes and intercepts

Lets try to add slopes varying by sex to intercepts

```{r}
m.3 <- 
  brm(data = d, 
      family = gaussian,
      cand_competency ~ 0 + cand_smile + # separate intercept for each smile type
        (1 + cand_sex || cand_id),        # uncorrelated random slope and intercept
      prior = c(prior(normal(0.5, 0.25), class = b),
                prior(exponential(1), class = sigma)),
      iter = 3000, warmup = 1000, chains = 4, cores = 4,
      control = list(adapt_delta = 0.98),
      seed = 3,
      file = "fits/m.3")
```

```{r}
print(m.3)
```



```{r}
mcmc_plot(m.2, pars = "b_")
```
The estimates are quite the same as in 2nd model 

Just for the sake of and experiment I will try an alternative model specification

```{r}
m.4 <- 
  brm(data = d, 
      family = gaussian,
      cand_competency ~ 0 + cand_smile + cand_sex:resp_sex + (1 | cand_id),
      prior = c(prior(normal(0, 1), class = b),
                prior(exponential(1), class = sigma)),
      control = list(adapt_delta = 0.98),
      iter = 4000, warmup = 2000, chains = 4, cores = 4,
      seed = 4,
      file = "fits/m.4")
```

```{r}
print(m.4)
```
 
 This est. errors looks huge. 
 Seems that is because of the multicolinearity
 
```{r}
mcmc_plot(m.4, pars = "cand_sexF")
```


```{r}
mcmc_plot(m.4, pars = "cand_sexM")
```

### Compare models 

```{r}
m.1 <- add_criterion(m.1, criterion = "loo")
m.2 <- add_criterion(m.2, criterion = "loo")
m.3 <- add_criterion(m.3, criterion = "loo")
m.4 <- add_criterion(m.4, criterion = "loo")
```

```{r}
loo_compare(m.1, m.2, m.3, m.4, criterion = "loo") %>% 
  print(simplify = F)
```

As expected, the simplest first model performs much worse 
There is no much of a difference between second and third model 
Fourth performs slightly better then others, but it suffers from multicollinearity


## model with all the data



```{r}
get_prior(data = d, 
      family = gaussian,
      cand_competency ~ 0 + cand_smile + cand_sex + (1 | cand_id) +        
        resp_sex + resp_hire)
```


```{r}
m.5 <- 
  brm(data = d, 
      family = gaussian,
      cand_competency ~ 0 + cand_smile + cand_sex +
         resp_sex + resp_hire + (1 | cand_id),        
      prior = c(prior(normal(0, 0.5), class = b),
                prior(exponential(1), class = sigma)),
      iter = 4000, warmup = 2000, chains = 4, cores = 4,
      seed = 4,
      file = "fits/m.5")
```

```{r}
print(m.5)
```
This seem much better than 4th model. Standard errors are much narrower.

```{r}
m.5 <- add_criterion(m.5, criterion = "loo")
```

```{r}
loo_compare(m.2, m.4, m.5, criterion = "loo") %>% 
  print(simplify = F)
```



# Cummulative link Model

As I wrote treating ordered categorical outcome as a continuous variable generally 
is not the best idea. 
Lets do it in a proper way



```{r}
m.6 <- 
  brm(data = d, 
      family = cumulative,
      cand_competency_fct ~ 1 + cand_smile,
      prior = c(prior(normal(0, 1.5), class = Intercept),
                prior(normal(0, 0.5), class = b)),
      iter = 2000, warmup = 1000, cores = 4, chains = 4,
      seed = 12,
      file = "fits/m.6")
```

```{r}
print(m.6)
```

```{r}
m.7 <- 
  brm(data = d, 
      family = cumulative,
      cand_competency_fct ~ 1 + cand_smile + cand_sex + (1 | cand_id),
      prior = c(prior(normal(0, 2), class = Intercept),
                prior(normal(0, 0.5), class = b)),
      iter = 2000, warmup = 1000, cores = 4, chains = 4,
      seed = 12,
      file = "fits/m.7")
```

```{r}
print(m.7)
```

```{r}
mcmc_plot(m.7, pars = "b_cand")
```



```{r}
m.8 <- 
  brm(data = d, 
      family = cumulative,
      cand_competency_fct ~ 1 + cand_smile + cand_sex + (1 | cand_id),
      prior = c(prior(normal(0, 2), class = Intercept),
                prior(normal(0, 0.5), class = b)),
      iter = 2000, warmup = 1000, cores = 4, chains = 4,
      seed = 12,
      file = "fits/m.8")
```